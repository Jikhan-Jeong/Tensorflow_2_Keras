{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nov 29, 2019 Keras Mnist Tutorial\n",
    "* Name: Jikhan Jeong\n",
    "* Ref: https://www.tensorflow.org/guide/keras/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/cahnrs/jikhan.jeong/keras\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  tf.keras.Sequential\n",
    "* MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adds a densely-connected layer with 64 units to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adds a densely-connected layer with 64 units to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a softmax layer with 10 output units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "# This short introduction uses Keras to:\n",
    "* Build a neural network that classifies images.\n",
    "* Train this neural network.\n",
    "* And, finally, evaluate the accuracy of the model.\n",
    "* Ref: https://www.tensorflow.org/tutorials/quickstart/beginner\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the tf.keras.Sequential model by stacking layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax') # multlabel = 10 digits\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2979 - accuracy: 0.9133\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1427 - accuracy: 0.9575\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1059 - accuracy: 0.9681\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0880 - accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0749 - accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2adc32a97750>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.0352 - accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06922037249235437, 0.9793]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "# Configure the layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are many tf.keras.layers available.\n",
    "\n",
    "* **activation**: Set the activation function for the layer. This parameter is specified by the name of a built-in function or as a callable object. By default, no activation is applied.\n",
    "* **kernel_initializer and bias_initializer**: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer.\n",
    "* **kernel_regularizer and bias_regularizer**: The regularization schemes that apply the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, no regularization is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras.Model.compile takes three important arguments:\n",
    "  \n",
    "* optimizer: This object specifies the training procedure. Pass it optimizer instances from the tf.keras.optimizers module, such as tf.keras.optimizers.Adam or tf.keras.optimizers.SGD. If you just want to use the default parameters, you can also specify optimizers via strings, such as 'adam' or 'sgd'.\n",
    "* loss: The function to minimize during optimization. Common choices include mean square error (mse), categorical_crossentropy, and binary_crossentropy. Loss functions are specified by name or by passing a callable object from the tf.keras.losses module.  \n",
    "* metrics: Used to monitor training. These are string names or callables from the tf.keras.metrics module.   \n",
    "* Additionally, to make sure the model trains and evaluates eagerly, you can make sure to pass run_eagerly=True as a parameter to compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train from NumPy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)), # input size 32\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 40.7966 - accuracy: 0.0990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 230.2558 - accuracy: 0.1130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 1085.2515 - accuracy: 0.0960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 2343.6339 - accuracy: 0.1060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 4156.8732 - accuracy: 0.1030\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 6363.9127 - accuracy: 0.0890\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 9071.8772 - accuracy: 0.1230\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 15113.2143 - accuracy: 0.0980\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 17803.1758 - accuracy: 0.0950\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 29264.5222 - accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aeb6ada2d50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 48.6436 - accuracy: 0.1150 - val_loss: 86.7829 - val_accuracy: 0.1100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 200.0222 - accuracy: 0.0960 - val_loss: 411.7444 - val_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 1094.1955 - accuracy: 0.1110 - val_loss: 1210.0069 - val_accuracy: 0.1100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 3430.2201 - accuracy: 0.0920 - val_loss: 4570.9439 - val_accuracy: 0.1100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 4431.7121 - accuracy: 0.0960 - val_loss: 5073.4842 - val_accuracy: 0.0900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 8284.0287 - accuracy: 0.0950 - val_loss: 6153.4189 - val_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 13432.9633 - accuracy: 0.1050 - val_loss: 16071.4217 - val_accuracy: 0.1200\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 24219.0550 - accuracy: 0.1030 - val_loss: 31037.5344 - val_accuracy: 0.0900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 29688.2516 - accuracy: 0.1220 - val_loss: 35018.1314 - val_accuracy: 0.1300\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 33345.7601 - accuracy: 0.0770 - val_loss: 36276.8789 - val_accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aeb6b63b6d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))\n",
    "# epochs: Training is structured into epochs. An epoch is one iteration over the entire input data (this is done in smaller batches).\n",
    "\n",
    "# batch_size: When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch. \n",
    "# Be aware that the last batch may be smaller if the total number of samples is not divisible by the batch size.\n",
    "\n",
    "# validation_data: When prototyping a model, you want to easily monitor its performance on some validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
